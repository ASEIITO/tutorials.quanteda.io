---
title: Different encodings
weight: 40
chapter: false
draft: false
---

```{r, message=FALSE}
knitr::opts_chunk$set(collapse = TRUE)
library(quanteda)

# Load the readtext package
require(readtext)

# Get the data directory from readtext
data_dir <- system.file("extdata/", package = "readtext")
```

## Read files with different encodings

Sometimes files of the same type have different encodings. If the encoding of a file is included in the file name, we can extract this information and import the texts correctly. 

```{r}
# create a temporary directory to extract the .zip file
FILEDIR <- tempdir()
# unzip file
unzip(system.file("extdata", "data_files_encodedtexts.zip", package = "readtext"), exdir = FILEDIR)
```

Here, we will get the encoding from the filenames themselves.

```{r}
# get encoding from filename
filenames <- list.files(FILEDIR, "^(Indian|UDHR_).*\\.txt$")

head(filenames)

# Strip the extension
filenames <- gsub(".txt$", "", filenames)
parts <- strsplit(filenames, "_")
fileencodings <- sapply(parts, "[", 3)

head(fileencodings)

# Check whether certain file encodings are not supported
notAvailableIndex <- which(!(fileencodings %in% iconvlist()))
fileencodings[notAvailableIndex]
```

If we read the text files without specifying the encoding, we get erroneously formatted text. To avoid this, we determine the `encoding` using the character object `fileencoding` created above. 

We can also add `docvars` based on the filenames.

```{r}
data_txts <- readtext(paste0(data_dir, "/data_files_encodedtexts.zip"), 
                 encoding = fileencodings,
                 docvarsfrom = "filenames", 
                 docvarnames = c("document", "language", "input_encoding"))
print(data_txts, n = 50)
```

From this file we can easily create a **quanteda** `corpus` object.

```{r}
corpus_txts <- corpus(data_txts)
summary(corpus_txts, 5)
```
