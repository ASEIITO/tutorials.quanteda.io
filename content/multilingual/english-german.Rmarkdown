---
title: English and German
weight: 10
draft: false
---

{{% author %}}By Kohei Watanabe{{% /author %}} 

```{r, message=FALSE}
require(quanteda)
require(quanteda.corpora)
options(width = 110)
```

`data_corpus_udhr` contains the Universal Declaration of Human Rights in multiple languages including Arabic. 

## English 

After tokenization, we remove grammatical words using `stopwords("ar", source = "marimo")`. We can improve tokenization by removing all non-Arabic letters by `"^[\\p{script=Arab}]+$"`.

Result should be read from right-to-left order.

```{r}
corp_eng <- corpus_reshape(data_corpus_udhr["eng"], to = "paragraphs")
toks_eng <- tokens(corp_eng, remove_punct = TRUE, remove_numbers = TRUE) %>% 
  tokens_select("^[\\p{script=Latin}]+$", valuetype = "regex") %>% 
  tokens_remove(stopwords("en", source = "marimo"))
print(toks_eng[2], max_ndoc = 1, max_ntoken = -1)
```

```{r}
# create a document-feature matrix
dfmat_eng <- dfm(toks_eng)
print(dfmat_eng)
```

## German

```{r}
corp_ger <- corpus_reshape(data_corpus_udhr["deu_1996"], to = "paragraphs")
toks_ger <- tokens(corp_ger, remove_punct = TRUE, remove_numbers = TRUE) %>% 
  tokens_select("^[\\p{script=Latn}]+$", valuetype = "regex") %>% 
  tokens_remove(stopwords("de", source = "marimo"))
print(toks_ger[2], max_ndoc = 1, max_ntoken = -1)
```

```{r}
dfmat_ger <- dfm(toks_ger)
print(dfmat_ger)
```
